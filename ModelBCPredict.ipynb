{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preliminary-coffee",
   "metadata": {},
   "source": [
    "## Using the ONNX model file for predictions\n",
    "### In this Notebook we take the model trained, saved in ONNX format and we do some predictions using a sampled test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "absent-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random as rn\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# conda env: mlcpuv1\n",
    "import keras2onnx\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.3.1\n",
      "ONNX runtime version 1.4.0\n",
      "keras2onnx version 1.7.0\n"
     ]
    }
   ],
   "source": [
    "# check TF version (> 2.3)\n",
    "print('TF version', tf.__version__)\n",
    "print('ONNX runtime version', rt.__version__)\n",
    "print('keras2onnx version', keras2onnx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-writing",
   "metadata": {},
   "source": [
    "### prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abroad-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of samples for (total, train, valid, test): 569 398 85 86\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset for test\n",
    "\n",
    "# we take the dataset from Sklearn\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "# I prefer working with Dataframe\n",
    "orig_df = data.frame\n",
    "\n",
    "# we must rename columns, to remove spaces in names\n",
    "# otherwise we get problems with ONNX\n",
    "\n",
    "# substitute all spaces with _\n",
    "dict_columns = {}\n",
    "\n",
    "for col in orig_df.columns:\n",
    "    dict_columns[col] = col.replace(\" \", \"_\")\n",
    "\n",
    "orig_df = orig_df.rename(columns=dict_columns)\n",
    "\n",
    "# Split the dataset in train, valid, test\n",
    "\n",
    "N_TOTAL = orig_df.shape[0]\n",
    "FRAC_TRAIN = 0.7\n",
    "FRAC_VALID = 0.15\n",
    "\n",
    "N_TRAIN = int(N_TOTAL * FRAC_TRAIN)\n",
    "N_VALID = int(N_TOTAL * FRAC_VALID)\n",
    "N_TEST = N_TOTAL - N_TRAIN - N_VALID\n",
    "\n",
    "print('Numbers of samples for (total, train, valid, test):', N_TOTAL, N_TRAIN, N_VALID, N_TEST)\n",
    "\n",
    "# shuffle the data\n",
    "orig_df = orig_df.sample(frac=1.)\n",
    "\n",
    "df_train = orig_df.iloc[:N_TRAIN]\n",
    "df_valid = orig_df.iloc[N_TRAIN:N_TRAIN+N_VALID]\n",
    "df_test = orig_df.iloc[N_TRAIN+N_VALID:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert in TF dataset\n",
    "#adapted from https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "def df_to_dataset(df, predictor,  batch_size=32, shuffle=True):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(predictor)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    \n",
    "    if shuffle:\n",
    "        # don't shuffle test\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "        \n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "political-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take only the test dataset\n",
    "ds_test = df_to_dataset(df_test, 'target', batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-detective",
   "metadata": {},
   "source": [
    "### load the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "anonymous-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OK\n",
      "Loading OK\n"
     ]
    }
   ],
   "source": [
    "# load the ONNX model\n",
    "ONNX_MODEL_FILE = 'modelbc-artifact/modelbc.onnx'\n",
    "\n",
    "# first, a function to load the model and create an ONNX session\n",
    "def create_session(onnx_file_name, print_info=False):\n",
    "    sess = rt.InferenceSession(onnx_file_name)\n",
    "    \n",
    "    print('Loading OK')\n",
    "    \n",
    "    if print_info:\n",
    "        print(\"ONNX model expects \", len(sess.get_inputs()), 'features:')\n",
    "        # prints names of features\n",
    "        for n, input in enumerate(sess.get_inputs()):\n",
    "            print(input.name)\n",
    "        \n",
    "    return sess\n",
    "\n",
    "# build the input as expected from ONNX runtime\n",
    "def build_input_feed(f_batch):\n",
    "    # input: the features_batch as extracted from TF dataset\n",
    "    # devo costruire il dict come se lo aspetta onnx\n",
    "    \n",
    "    input_dict = {}\n",
    "    \n",
    "    # ogni feature Ã¨ un singolo valore\n",
    "    for col in f_batch.keys():\n",
    "        # get the numpy array of values\n",
    "        values = f_batch[col].numpy()\n",
    "        n_rows = len(values)\n",
    "        input_dict[col] = values.reshape((n_rows, 1))\n",
    "    \n",
    "    # input_feed is the dictionary input to ONNX model\n",
    "    # for every feature a column vector (n_rows, 1)\n",
    "    return input_dict\n",
    "\n",
    "def onnx_predict(f_batch, sess=create_session(ONNX_MODEL_FILE)):\n",
    "    # transform the input\n",
    "    input_feed = build_input_feed(f_batch)\n",
    "    \n",
    "    # run inference\n",
    "    pred_onnx = sess.run(None, input_feed)\n",
    "    \n",
    "    # build output\n",
    "    output = {}\n",
    "    output['probs'] = pred_onnx[0]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def predict(input_dict, sess=create_session(ONNX_MODEL_FILE)):\n",
    "    \n",
    "    input_feed = {}\n",
    "    \n",
    "    for col in input_dict.keys():\n",
    "        # get the numpy array of values\n",
    "        np_values = np.array(input_dict[col])\n",
    "        n_rows = len(np_values)\n",
    "        \n",
    "        input_feed[col] = np_values.reshape((n_rows, 1))\n",
    "        \n",
    "    pred_onnx = sess.run(None, input_feed)\n",
    "        \n",
    "    output = {}\n",
    "    output['probs'] = pred_onnx[0]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-pastor",
   "metadata": {},
   "source": [
    "### do the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "auburn-astronomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch n. 1\n",
      "Predictions: [3.4209043e-02 9.9927604e-01 7.8657955e-02 1.9699335e-05 9.9996507e-01\n",
      " 9.9995029e-01 8.5532665e-05 9.9990296e-01 9.3904138e-04 0.0000000e+00\n",
      " 9.9976373e-01 9.9999046e-01 4.3094158e-05 9.9998891e-01 9.9797368e-01\n",
      " 1.1874348e-02]\n",
      "Time (sec.) for batch prediction: 0.002\n",
      "\n",
      "Batch n. 2\n",
      "Predictions: [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3551297e-01 2.4139881e-06\n",
      " 1.4573336e-05 1.2516975e-06 2.6822090e-07 8.0625677e-01 7.2739691e-02\n",
      " 9.9982810e-01 9.9993289e-01 2.8401023e-01 6.2039793e-03 2.9720610e-01\n",
      " 9.9933505e-01]\n",
      "Time (sec.) for batch prediction: 0.002\n",
      "\n",
      "Batch n. 3\n",
      "Predictions: [9.9850005e-01 3.9249659e-05 9.9999654e-01 7.7486038e-06 9.9508357e-01\n",
      " 9.7657365e-01 9.9995804e-01 4.9226868e-01 9.9983120e-01 9.9553525e-01\n",
      " 9.9377042e-01 9.9997973e-01 9.9999344e-01 4.3253601e-03 6.7058474e-02\n",
      " 9.9996686e-01]\n",
      "Time (sec.) for batch prediction: 0.002\n",
      "\n",
      "Batch n. 4\n",
      "Predictions: [6.2584877e-07 9.8074281e-01 9.5055419e-01 0.0000000e+00 9.9995172e-01\n",
      " 1.4218688e-04 9.9999833e-01 9.9975479e-01 2.9444695e-05 3.0151755e-02\n",
      " 9.9947411e-01 8.0764294e-06 3.3648700e-02 1.2665987e-05 9.9497360e-01\n",
      " 9.9939620e-01]\n",
      "Time (sec.) for batch prediction: 0.001\n",
      "\n",
      "Batch n. 5\n",
      "Predictions: [8.9252859e-02 9.9999040e-01 9.9633884e-01 9.9989349e-01 7.2748333e-01\n",
      " 9.9724132e-01 9.9992037e-01 9.9982208e-01 1.7464161e-05 2.0048320e-03\n",
      " 6.7836046e-04 9.7104096e-01 9.9999809e-01 9.6549076e-01 9.9739295e-01\n",
      " 9.9995005e-01]\n",
      "Time (sec.) for batch prediction: 0.002\n",
      "\n",
      "Batch n. 6\n",
      "Predictions: [9.9517524e-01 6.7520106e-01 8.6426735e-07 9.9999285e-01 3.5762787e-07\n",
      " 9.9999815e-01]\n",
      "Time (sec.) for batch prediction: 0.004\n",
      "\n",
      "\n",
      "ONNX test OK.\n"
     ]
    }
   ],
   "source": [
    "# this way I take only the feature batch out of a dataset batch\n",
    "\n",
    "# do the test on the entire test dataset\n",
    "for i, f_batch in enumerate(iter(ds_test)):\n",
    "    print('Batch n.', i+1)\n",
    "    \n",
    "    # needed\n",
    "    f_batch = f_batch[0]\n",
    "    \n",
    "    tStart = time.time()\n",
    "    \n",
    "    onnx_probs = onnx_predict(f_batch)\n",
    "    tEla = time.time() - tStart\n",
    "    print('Predictions:', onnx_probs['probs'].ravel())\n",
    "    \n",
    "    print('Time (sec.) for batch prediction:', round(tEla, 3))\n",
    "    print('')\n",
    "    \n",
    "print('')\n",
    "print('ONNX test OK.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-portfolio",
   "metadata": {},
   "source": [
    "#### Ok, to do a prediction on 16 samples it takes around 2 msec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-threshold",
   "metadata": {},
   "source": [
    "### Now check using as input the JSON file sample1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "departmental-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from file\n",
    "data_str = open('sample1.json', 'r').read()\n",
    "\n",
    "input_dict = json.loads(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "proved-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_probs = predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "indoor-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probs': array([[0.0000000e+00],\n",
       "        [9.9976540e-01],\n",
       "        [2.3906797e-02],\n",
       "        [9.9380422e-01],\n",
       "        [8.5192496e-01],\n",
       "        [9.9996710e-01],\n",
       "        [9.9933505e-01],\n",
       "        [9.9992895e-01],\n",
       "        [9.9999237e-01],\n",
       "        [2.3245811e-06],\n",
       "        [9.9956256e-01],\n",
       "        [1.7464161e-05],\n",
       "        [2.9324174e-02],\n",
       "        [1.1874348e-02],\n",
       "        [9.9999654e-01],\n",
       "        [9.6708000e-01]], dtype=float32)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-exclusive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
